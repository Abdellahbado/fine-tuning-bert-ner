{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'tokens'],\n",
       "        num_rows: 245\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['labels', 'tokens'],\n",
       "        num_rows: 62\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import *\n",
    "\n",
    "file_path = \"datasets/ner-large-dataset-train.json\"\n",
    "\n",
    "# Load the dataset from the file\n",
    "dataset = load_dataset('json', data_files=file_path)\n",
    "\n",
    "train_valid = dataset['train'].train_test_split(test_size=0.2)\n",
    "train = train_valid['train']\n",
    "valid = train_valid['test']\n",
    "\n",
    "ds = DatasetDict({\"train\": train, \"valid\": valid})\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(label for example in train for label in example[\"labels\"])\n",
    "label2id = {label: id for id, label in enumerate(unique_labels)}\n",
    "id2label = {id: label for label, id in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-Experience_Level',\n",
       " 2: 'B-Job_Role',\n",
       " 3: 'B-Domain',\n",
       " 4: 'B-Job_role',\n",
       " 5: 'B-Skill'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-Experience_Level': 1,\n",
       " 'B-Job_Role': 2,\n",
       " 'B-Domain': 3,\n",
       " 'B-Job_role': 4,\n",
       " 'B-Skill': 5}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = ds['train']['labels']\n",
    "labels_valid = ds['valid']['labels']\n",
    "encoded_labels_train = []\n",
    "for label_sequence in labels_train:\n",
    "    encoded_sequence = [label2id[label] for label in label_sequence]\n",
    "    encoded_labels_train.append(encoded_sequence)\n",
    "    \n",
    "encoded_labels_valid = []\n",
    "for label_sequence in labels_valid:\n",
    "    encoded_sequence = [label2id[label] for label in label_sequence]\n",
    "    encoded_labels_valid.append(encoded_sequence)\n",
    "\n",
    "encoded_dataset = ds['train'].add_column('encoded_labels', encoded_labels_train)\n",
    "encoded_valid = ds['valid'].add_column('encoded_labels', encoded_labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens:  ['We', 'are', 'seeking', 'an', 'experienced', 'Senior', 'Software', 'Engineer', 'with', 'expertise', 'in', 'Python', ',', 'Django', ',', 'and', 'RESTful', 'API', 'development', 'to', 'join', 'our', 'backend', 'team', '.', 'The', 'ideal', 'candidate', 'should', 'have', '5+', 'years', 'of', 'experience', 'in', 'building', 'scalable', 'and', 'high-performance', 'web', 'applications', 'in', 'the', 'tech', 'industry', '.']\n",
      "labels:  ['O', 'O', 'O', 'O', 'O', 'B-Experience_Level', 'B-Experience_Level', 'B-Job_Role', 'O', 'O', 'O', 'O', 'B-Skill', 'O', 'B-Skill', 'O', 'B-Skill', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Domain', 'O']\n",
      "encoded_labels:  [0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 5, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0]\n",
      "tokens:  ['A', 'leading', 'healthcare', 'company', 'is', 'looking', 'for', 'a', 'Mid-level', 'Data', 'Scientist', 'proficient', 'in', 'machine', 'learning', 'algorithms,', 'data', 'mining,', 'and', 'Python.', 'Experience', 'with', 'TensorFlow', 'or', 'PyTorch', 'is', 'a', 'plus.', 'Responsibilities', 'include', 'building', 'predictive', 'models,', 'conducting', 'data', 'analysis,', 'and', 'collaborating', 'with', 'cross-functional', 'teams.']\n",
      "labels:  ['O', 'O', 'B-Domain', 'O', 'O', 'O', 'O', 'B-Experience_Level', 'B-Job_Role', 'O', 'O', 'B-Skill', 'O', 'B-Skill', 'B-Skill', 'O', 'B-Skill', 'O', 'O', 'O', 'B-Skill', 'O', 'B-Skill', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "encoded_labels:  [0, 0, 3, 0, 0, 0, 0, 1, 2, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tokens:  ['We', 'are', 'hiring', 'an', 'Entry-level', 'Frontend', 'Developer', 'with', 'strong', 'skills', 'in', 'JavaScript,', 'React,', 'and', 'CSS', 'to', 'join', 'our', 'e-commerce', 'team.', 'The', 'ideal', 'candidate', 'should', 'have', 'a', 'passion', 'for', 'building', 'responsive', 'and', 'user-friendly', 'web', 'applications.', 'Knowledge', 'of', 'Redux', 'and', 'experience', 'with', 'Agile', 'methodologies', 'is', 'preferred.']\n",
      "labels:  ['O', 'O', 'O', 'B-Experience_Level', 'B-Job_Role', 'O', 'O', 'O', 'O', 'B-Skill', 'O', 'B-Skill', 'O', 'B-Skill', 'O', 'O', 'O', 'B-Domain', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Skill', 'O', 'O', 'O', 'O']\n",
      "encoded_labels:  [0, 0, 0, 1, 2, 0, 0, 0, 0, 5, 0, 5, 0, 5, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('tokens: ', encoded_dataset[i]['tokens'])\n",
    "    print('labels: ', encoded_dataset[i]['labels'])\n",
    "    print('encoded_labels: ', encoded_dataset[i]['encoded_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f70889072334f7abd0c49ddd834a84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05555efe06d948b28fb92c22e819061f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def tokenize_and_align_tags(records):\n",
    "    # Tokenize the input words. This will break words into subtokens if necessary.\n",
    "    # For instance, \"ChatGPT\" might become [\"Chat\", \"##G\", \"##PT\"].\n",
    "    tokenized_results = tokenizer(records[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    input_tags_list = []\n",
    "\n",
    "    # Iterate through each set of tags in the records.\n",
    "    for i, given_tags in enumerate(records[\"encoded_labels\"]):\n",
    "        # Get the word IDs corresponding to each token. This tells us to which original word each token corresponds.\n",
    "        word_ids = tokenized_results.word_ids(batch_index=i)\n",
    "\n",
    "        previous_word_id = None\n",
    "        input_tags = []\n",
    "\n",
    "        # For each token, determine which tag it should get.\n",
    "        for wid in word_ids:\n",
    "            # If the token does not correspond to any word (e.g., it's a special token), set its tag to -100.\n",
    "            if wid is None:\n",
    "                input_tags.append(-100)\n",
    "            # If the token corresponds to a new word, use the tag for that word.\n",
    "            elif wid != previous_word_id:\n",
    "                if wid < len(given_tags):\n",
    "                    input_tags.append(given_tags[wid])\n",
    "                else:\n",
    "                    input_tags.append(-100)\n",
    "            # If the token is a subtoken (i.e., part of a word we've already tagged), set its tag to -100.\n",
    "            else:\n",
    "                input_tags.append(-100)\n",
    "            previous_word_id = wid\n",
    "\n",
    "        input_tags_list.append(input_tags)\n",
    "\n",
    "    # Add the assigned tags to the tokenized results.\n",
    "    # In the Hugging Face Transformers library, a model recognizes the labels parameter\n",
    "    # for computing losses along with logits (predictions)\n",
    "    tokenized_results[\"labels\"] = input_tags_list\n",
    "\n",
    "    return tokenized_results\n",
    "\n",
    "tokenized_encoded_dataset = encoded_dataset.map(tokenize_and_align_tags, batched=True)\n",
    "tokenized_encoded_valid = encoded_valid.map(tokenize_and_align_tags, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dslim/bert-base-NER and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"dslim/bert-base-NER\", num_labels=len(id2label), id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-Experience_Level', 'B-Job_Role', 'B-Domain', 'B-Job_role', 'B-Skill']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = [label for id, label in sorted(id2label.items())]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdallah/anaconda3/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_finetuned_ner_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdallah/anaconda3/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a855277d5a4345b40f2dd782eaa709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a1275e293c4cf1ae6843fc79db4e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5960123538970947, 'eval_precision': 0.8107255520504731, 'eval_recall': 0.7648809523809523, 'eval_f1': 0.7871362940275649, 'eval_accuracy': 0.8094534711964549, 'eval_runtime': 2.4673, 'eval_samples_per_second': 25.128, 'eval_steps_per_second': 3.242, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9baac1df53844ce78b30f860ade51f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6159459352493286, 'eval_precision': 0.782991202346041, 'eval_recall': 0.7946428571428571, 'eval_f1': 0.7887740029542099, 'eval_accuracy': 0.8079763663220089, 'eval_runtime': 2.5714, 'eval_samples_per_second': 24.111, 'eval_steps_per_second': 3.111, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b44acc4731480e810d31a3267da9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6356953382492065, 'eval_precision': 0.7905604719764012, 'eval_recall': 0.7976190476190477, 'eval_f1': 0.7940740740740742, 'eval_accuracy': 0.8094534711964549, 'eval_runtime': 2.5935, 'eval_samples_per_second': 23.905, 'eval_steps_per_second': 3.085, 'epoch': 3.0}\n",
      "{'train_runtime': 167.8537, 'train_samples_per_second': 4.379, 'train_steps_per_second': 0.554, 'train_loss': 0.20442570922195272, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=93, training_loss=0.20442570922195272, metrics={'train_runtime': 167.8537, 'train_samples_per_second': 4.379, 'train_steps_per_second': 0.554, 'train_loss': 0.20442570922195272, 'epoch': 3.0})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_encoded_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    eval_dataset=tokenized_encoded_valid,  # Pass the validation dataset\n",
    "    compute_metrics= compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/abdallah/Documents/new AI/Transformers/NER-fine-tuning/my_finetuned_ner_model/tokenizer_config.json',\n",
       " '/home/abdallah/Documents/new AI/Transformers/NER-fine-tuning/my_finetuned_ner_model/special_tokens_map.json',\n",
       " '/home/abdallah/Documents/new AI/Transformers/NER-fine-tuning/my_finetuned_ner_model/vocab.txt',\n",
       " '/home/abdallah/Documents/new AI/Transformers/NER-fine-tuning/my_finetuned_ner_model/added_tokens.json',\n",
       " '/home/abdallah/Documents/new AI/Transformers/NER-fine-tuning/my_finetuned_ner_model/tokenizer.json')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path=\"/home/abdallah/Documents/new AI/Transformers/NER-fine-tuning/my_finetuned_ner_model\"\n",
    "\n",
    "\n",
    "model.save_pretrained(model_path)\n",
    "\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "# Load pre-trained BERT model configuration\n",
    "pretrained_config = BertConfig.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "# Modify configuration parameters for fine-tuning\n",
    "pretrained_config.num_labels = len(id2label)  # Set the number of labels\n",
    "pretrained_config.id2label = id2label  # Set the id to label mapping\n",
    "pretrained_config.label2id = label2id  # Set the label to id mapping\n",
    "pretrained_config.ignore_mismatched_sizes = True  # Ignore mismatched sizes\n",
    "\n",
    "# Serialize modified configuration object to JSON string\n",
    "config_json = pretrained_config.to_json_string()\n",
    "\n",
    "# Save JSON string to config.json file\n",
    "with open(\"config.json\", \"w\") as config_file:\n",
    "    config_file.write(config_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Create a pipeline for named entity recognition (NER)\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Junior, Type: B-Experience_Level\n",
      "Entity: Data, Type: B-Job_Role\n",
      "Entity: Scientist, Type: B-Job_Role\n",
      "Entity: machine, Type: B-Skill\n"
     ]
    }
   ],
   "source": [
    "# Example input text\n",
    "tokens = \"Junior Data Scientist and machine learning developer\"\n",
    "results = ner_pipeline(tokens)\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(f\"Entity: {result['word']}, Type: {result['entity']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity: Junior, Type: B-Experience_Level\n",
    "# Entity: Data, Type: B-Job_Role\n",
    "# Entity: Scientist, Type: B-Job_Role\n",
    "# Entity: machine, Type: B-Skill\n",
    "# Entity: learning, Type: B-Skill\n",
    "# Entity: Python, Type: B-Skill\n",
    "# Entity: rub, Type: B-Skill"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
